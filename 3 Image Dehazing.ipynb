{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce49a602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import sys\n",
    "from numpy import asarray\n",
    "np.set_printoptions(threshold=100)\n",
    "import scipy.stats as st\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import convolve2d \n",
    "from torch.nn.quantized import functional as qF\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import math\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ee35fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ideas for speeding up: flatten image and use array access instead of double for loops, time complexity from O(n^2) to O(n)\n",
    "def get_dark_channel(im,sz):\n",
    "    b,g,r = cv2.split(im)\n",
    "    dc = cv2.min(cv2.min(r,g),b);\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(sz,sz))\n",
    "    dark = cv2.erode(dc,kernel)\n",
    "    return dark\n",
    "\n",
    "\n",
    "def get_atmosphere(im, darkch, p):\n",
    "    M, N = darkch.shape #get shape of dark channel\n",
    "    flatI=im.flatten().reshape(409600,3)\n",
    "    flatdark = darkch.flatten() #contiguously flatten the dark channel\n",
    "    searchidx = (flatdark.argsort()[:round(M * N * p)])  # find top M * N * p indexes in the dark channel\n",
    "    r=[]\n",
    "    g=[]\n",
    "    b=[]\n",
    "    actualPixelIntensities=[flatI[searchidx] for index in searchidx]\n",
    "    for intensity in actualPixelIntensities:\n",
    "        r.append(intensity[0])\n",
    "        g.append(intensity[1])\n",
    "        b.append(intensity[2])\n",
    "    return([np.max(b),np.max(g),np.max(r)])\n",
    "\n",
    "\n",
    "def get_transmission(I, A, omega, w):\n",
    "    map=(1 - omega * get_dark_channel(I / A, w))\n",
    "    map=map*255\n",
    "    map=map.astype(np.uint8)\n",
    "    return(map) ## CVPR09, eq.12\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def Recover(im,t,A,tx = .01):\n",
    "\n",
    "    res = np.empty(im.shape,im.dtype);\n",
    "    t = cv2.max(t,tx);\n",
    "    \n",
    "\n",
    "    for ind in range(0,3):\n",
    "#         b,g,r=cv2.split(img)\n",
    "#         b=(((b-A[0])/t) + A[0])\n",
    "#         print(b)\n",
    "#         g=(((g-A[1])/t) + A[1])\n",
    "#         r=(((r-A[2])/t) + A[2])\n",
    "#         b=np.uint8(b)\n",
    "#         g=np.uint8(g)\n",
    "#         r=np.uint8(r)\n",
    "        res[:,:,ind] = ((im[:,:,ind]-A[ind])/t) + A[ind]\n",
    "#         finalimage=cv2.merge((g,b,r))\n",
    "        \n",
    "    res=res*255\n",
    "    res=res.astype(np.uint8)\n",
    "\n",
    "    return res\n",
    "\n",
    "def Guidedfilter(im,p,r,eps):\n",
    "    mean_I = cv2.boxFilter(im,cv2.CV_64F,(r,r));\n",
    "    mean_p = cv2.boxFilter(p, cv2.CV_64F,(r,r));\n",
    "    mean_Ip = cv2.boxFilter(im*p,cv2.CV_64F,(r,r));\n",
    "    cov_Ip = mean_Ip - mean_I*mean_p;\n",
    "\n",
    "    mean_II = cv2.boxFilter(im*im,cv2.CV_64F,(r,r));\n",
    "    var_I   = mean_II - mean_I*mean_I;\n",
    "\n",
    "    a = cov_Ip/(var_I + eps);\n",
    "    b = mean_p - a*mean_I;\n",
    "\n",
    "    mean_a = cv2.boxFilter(a,cv2.CV_64F,(r,r));\n",
    "    mean_b = cv2.boxFilter(b,cv2.CV_64F,(r,r));\n",
    "\n",
    "    q = mean_a*im + mean_b;\n",
    "    return q;\n",
    "\n",
    "def TransmissionRefine(im,et):\n",
    "    gray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY);\n",
    "    gray = np.float64(gray)/255;\n",
    "    r = 60;\n",
    "    eps = 0.0001;\n",
    "    t = Guidedfilter(gray,et,r,eps);\n",
    "\n",
    "    return t;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48675d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mpimg.imread(\"pipes/train/frame00315_lrgb_jpg.rf.e413c82778d73310c963d6a6bea50b7c.jpg\")\n",
    "\n",
    "if img is None:\n",
    "    print(\"NONE\")\n",
    "else:\n",
    "#     I = img.astype('float64')/255;\n",
    "    dark=get_dark_channel(img,3)\n",
    "    print(type(dark))\n",
    "#     darkimage=Image.fromarray(dark)\n",
    "#     darkimage.save(\"darkchannel2.png\")\n",
    "#     image = Image.open(\"darkchannel2.png\")\n",
    "#     plt.imshow(image, cmap='gray')\n",
    "    \n",
    "#     a=get_atmosphere(img,get_dark_channel(img,3), .01)\n",
    "#     t=get_transmission(img,a,.95,2)  ##smaller last value means higher resolution of image\n",
    "#     tr = TransmissionRefine(img,t);\n",
    "#     datat=Image.fromarray(tr)\n",
    "#     datat = datat.convert('RGB')\n",
    "#     datat.save(\"trasmission_map.png\")\n",
    "\n",
    "\n",
    "    \n",
    "#     J=Recover(img,tr,a,.1)\n",
    "#     Jt=Image.fromarray(J)\n",
    "#     Jt = Jt.convert('RGB')\n",
    "#     Jt.save(\"final.png\")\n",
    "# #     j=Image.open(\"final.png\")\n",
    "# #     plt.imshow(J)\n",
    "#     cv2.imwrite(\"final.png\",J*255);\n",
    "#     cv2.imshow('J',J);\n",
    "#     cv2.waitKey(0);\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c8d505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ccbe96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
